{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a DEBUG flag with values from '0' to '5'. Default is '0' which is OFF. \n",
    "# Use this cautiously - we are not validating for this\n",
    "\n",
    "DEBUG = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use h2o4gpu if you have it installed\n",
    "# Add a flag with Default as False. Don't change this unless your kernel uses h2o4gpu.\n",
    "h2o4gpu_enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Read the source file of raw commit data\n",
    "target_repo_dir = '/home/kc/Projects/data_files/target_repo_data/'\n",
    "target_repo_raw_data_file = 'MyPlace.git.csv'\n",
    "target_repo_commits = pd.read_csv(target_repo_dir+target_repo_raw_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the features from raw commit data\n",
    "def create_ml_frame(pred_commits,ext):\n",
    "    pred_commits = pred_commits[pred_commits['file_ext']==ext]\n",
    "    \n",
    "    pred_commits['total_changed'] = pred_commits['number_lines_added']+pred_commits['number_lines_removed']\n",
    "    pred_commits['feature_total_changed'] = (pred_commits['total_changed'] ** 0.7)\n",
    "\n",
    "    pred_commits['file_number_loc'].loc[pred_commits['file_number_loc'] == 0] = pred_commits['total_changed']\n",
    "    pred_commits['ratio_changed'] = pred_commits['total_changed']/pred_commits['file_number_loc']\n",
    "    \n",
    "    pred_commits['feature_rated_complexity'] = pred_commits['ratio_changed'] * pred_commits['file_complexity'] * \\\n",
    "                                                (pred_commits['total_changed'] ** 0.3)  \n",
    "    \n",
    "    pred_commits['feature_dmm_size'] = (pred_commits['total_changed'] ** 0.5) * pred_commits['dmm_unit_size']\n",
    "    pred_commits['feature_dmm_unit_complexity'] = (pred_commits['total_changed'] ** 0.5) * \\\n",
    "                                                    pred_commits['dmm_unit_complexity']\n",
    "    pred_commits['feature_dmm_unit_interfacing'] = (pred_commits['total_changed'] ** 0.5) * \\\n",
    "                                                    pred_commits['dmm_unit_interfacing']\n",
    "\n",
    "\n",
    "    pred_ml_commits = pred_commits[['hash','Author','Committer','committed_date','feature_total_changed',\n",
    "                                    'feature_rated_complexity', 'feature_dmm_unit_complexity',\n",
    "                                    'feature_dmm_size','feature_dmm_unit_interfacing']]\n",
    "\n",
    "    # Resetting the frame's index. It is required to retain the integrity of the frame\n",
    "    pred_ml_commits = pred_ml_commits.reset_index().drop(columns = 'index')\n",
    "\n",
    "    # Author/text column needs to be dropped before converting the all the fields into numeric types\n",
    "    pred_ml_commits_na = pred_ml_commits.drop(columns = ['Author','hash','Committer','committed_date'])\n",
    "\n",
    "    # Converting the fields to numeric types, filling the NaNs with zeros\n",
    "    pred_ml_commits_numeric = pred_ml_commits_na.apply(pd.to_numeric,errors ='coerce').fillna(0)\n",
    "\n",
    "    # Adding teh Author/text column back\n",
    "    pred_ml_commits_all_coloumns = pred_ml_commits_numeric.copy()\n",
    "    pred_ml_commits_all_coloumns['Author'] = pred_ml_commits['Author']\n",
    "    pred_ml_commits_all_coloumns['hash'] = pred_ml_commits['hash']\n",
    "    pred_ml_commits_all_coloumns['Committer'] = pred_ml_commits['Committer']\n",
    "    pred_ml_commits_all_coloumns['committed_date'] = pred_ml_commits['committed_date']\n",
    "    # We need to name this better. pred_ml_commits_all_coloumns ? I think the name is opposite of what this describes\n",
    "    #pred_ml_commits_numeric_na = pred_ml_commits_numeric.drop(columns=['Author','hash','committed_date','Committer'])\n",
    "    \n",
    "    return pred_ml_commits_numeric, pred_ml_commits_all_coloumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import glob\n",
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Find the file extensions for the target repo commits.\n",
    "#target_repo_commits['file_ext'] = \\\n",
    "#        target_repo_commits['file_new_path'].apply(lambda x:pathlib.Path(str(x)).suffix).\\\n",
    "#        apply(lambda x:re.split(r\"[^a-zA-Z0-9\\s\\++\\_\\-]\",x)[-1])\n",
    "#target_repo_commits.file_ext = target_repo_commits.file_ext.replace(r'^\\s*$', 'NoExt', regex=True)\n",
    "\n",
    "if DEBUG >=1:\n",
    "    print(len(target_repo_commits['file_ext'].unique()))\n",
    "\n",
    "# Get the list of file extension from the target repo data\n",
    "target_repo_file_exts = target_repo_commits['file_ext'].unique()\n",
    "\n",
    "# Scaling the data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Get the file names of saved GMM models. No idea whats happening below. Need to improve comment\n",
    "gmm_model_files = [f for f in listdir('/home/kc/Projects/data_files/sav_files/gmm_sav') if isfile(join('/home/kc/Projects/data_files/sav_files/gmm_sav', f))]\n",
    "file_ext_models = [x.split('_')[0] for x in gmm_model_files]\n",
    "\n",
    "# Folder having the GMM pickle files\n",
    "gmm_models_folder = '/home/kc/Projects/data_files/sav_files/gmm_sav/'\n",
    "\n",
    "# Folder having the xgboost trained classifiers\n",
    "xgboost_models_folder = '/home/kc/Projects/data_files/sav_files/xgboost_sav/'\n",
    "\n",
    "# Folder for storing results\n",
    "predictions_folder = '/home/kc/Projects/data_files/predictions/'\n",
    "\n",
    "# Remove any previous files. This is probably not needed\n",
    "files = glob.glob(predictions_folder+'*.csv')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "## Process the target repos mods against our trained files    \n",
    "for file_ext in target_repo_file_exts:\n",
    "    \n",
    "    if DEBUG >= 3:\n",
    "        print('Processing file extension: ', file_ext)\n",
    "        store_start = datetime.now()\n",
    "        print('starting at: ', store_start)\n",
    "    \n",
    "    # Prepare the features from raw data \n",
    "    target_repo_data_frame_numeric, target_repo_data_frame_all_coloumns = create_ml_frame(target_repo_commits, file_ext)\n",
    "    \n",
    "    ## Ensure that we have models for this file extension\n",
    "    if file_ext in file_ext_models:\n",
    "        xgboost_model_file = xgboost_models_folder+file_ext+'_xgboost_model.sav'\n",
    "        xboost_model = pickle.load(open(xgboost_model_file, 'rb'))\n",
    "        \n",
    "        # Use the xgboost model to predict the cluster\n",
    "        predicted_clusters = xboost_model.predict(target_repo_data_frame_numeric)\n",
    "        target_repo_data_frame_all_coloumns['predicted_cluster'] = predicted_clusters\n",
    "\n",
    "        ## Now use the GMM pickled models to calculate the probability of the mod belonging to predicted cluster\n",
    "        # First get the relevant GMM pickel file for this file type/extension\n",
    "        gmm_model_file = gmm_models_folder+file_ext+'_gmm_model_pickle.sav'\n",
    "        mix = pickle.load(open(gmm_model_file, 'rb'))\n",
    "        #pred_ml_commits_numeric_all = target_repo_data_frame_all_coloumns.drop(columns=['Author','hash','committed_date','Committer'])\n",
    "        \n",
    "        # Scale the data for GMM processing\n",
    "        data_scaled = scaler.fit_transform(target_repo_data_frame_numeric)\n",
    "        \n",
    "        # Put this in a pandas frame\n",
    "        cluster_frame = pd.DataFrame(data_scaled)\n",
    "        \n",
    "        # Not sure why we are doing this. I think this is redundant.\n",
    "        # gmm_hash_clusters = mix.predict(cluster_frame)\n",
    "        \n",
    "        # Get the 'real world' value of the centroids. We need these to calculate the 'score' of each mod. \n",
    "        gmm_centroids = mix.means_\n",
    "        real_centroids = scaler.inverse_transform(gmm_centroids)\n",
    "\n",
    "        # Write these to dataframe\n",
    "        real_centroids_dataFrame = pd.DataFrame(real_centroids, columns=['feature_total_changed',\n",
    "                                    'feature_rated_complexity', 'feature_dmm_unit_complexity',\n",
    "                                    'feature_dmm_size','feature_dmm_unit_interfacing'])\n",
    "                                                \n",
    "        # Add a column for summing all coloumns (https://github.com/kcramakrishna/cg/issues/10)\n",
    "        # This is basically assigning a 'real world value' to each centroid i.e. cluster\n",
    "        real_centroids_dataFrame['Sum_centroids'] = real_centroids_dataFrame.sum(axis = 1)\n",
    "        real_centroids_dataFrame['original_cluster_labels'] = real_centroids_dataFrame.index\n",
    "        \n",
    "        # Now we need to map the cluster labels to the 'sum of centroids' for that cluster \n",
    "        centroid_map={}\n",
    "        for i in range(real_centroids_dataFrame.shape[0]):\n",
    "            centroid_map[real_centroids_dataFrame['original_cluster_labels'].values[i]]=real_centroids_dataFrame['Sum_centroids'].values[i]\n",
    "        \n",
    "        # Initialise a coloumn for holding the probabilities of the prediction\n",
    "        probability_for_labels = np.zeros((len(predicted_clusters),1))\n",
    "        \n",
    "        # xgboost Gave the prediction, From GMM, get the probability of this prediction\n",
    "        # Need to understand the below lines in more depth\n",
    "        member_probs = mix.predict_proba(cluster_frame)\n",
    "        for i in range(len(predicted_clusters)):\n",
    "            probability_for_labels[i] = member_probs[i,predicted_clusters[i]]\n",
    "        \n",
    "        # Add the probabilities coloumn to the data Frame\n",
    "        target_repo_data_frame_all_coloumns['probablities'] = probability_for_labels\n",
    "        \n",
    "        # Look up the Sum of Centroids for each cluster for each mod and add it to the row.\n",
    "        target_repo_data_frame_all_coloumns['sum_centroid']=np.arange(0.0,target_repo_data_frame_all_coloumns.shape[0],1.0)\n",
    "        for i in range(target_repo_data_frame_all_coloumns.shape[0]):\n",
    "            target_repo_data_frame_all_coloumns['sum_centroid'].values[i]=centroid_map[target_repo_data_frame_all_coloumns['predicted_cluster'].values[i]]\n",
    "        \n",
    "        # Finally calculate the score for each mod in the target repo\n",
    "        target_repo_data_frame_all_coloumns['mod_score'] = target_repo_data_frame_all_coloumns['sum_centroid'] * target_repo_data_frame_all_coloumns['probablities']\n",
    "        \n",
    "        # Append these results to target_predictions file\n",
    "        with open(predictions_folder+'scores_'+target_repo_raw_data_file, 'a') as predictions_file:\n",
    "            target_repo_data_frame_all_coloumns.to_csv(predictions_file, mode='a', \\\n",
    "                                                       header=predictions_file.tell()==0)\n",
    "    else:\n",
    "        target_repo_data_frame_all_coloumns['predicted_cluster'] = 'No Model found'\n",
    "        target_repo_data_frame_all_coloumns['sum_centroid'] = 0\n",
    "        target_repo_data_frame_all_coloumns['probablities'] = 0\n",
    "        target_repo_data_frame_all_coloumns['mod_score'] = 0\n",
    "        with open(predictions_folder+'scores_'+target_repo_raw_data_file, 'a') as predictions_file:\n",
    "            target_repo_data_frame_all_coloumns.to_csv(predictions_file, mode='a', \\\n",
    "                                                       header=predictions_file.tell()==0)\n",
    "    if DEBUG >=2:\n",
    "            print(predictions_folder+'scores_'+target_repo_raw_data_file)    \n",
    "    \n",
    "    if DEBUG >=3:\n",
    "            store_end = datetime.now()\n",
    "            print('processing complete: ', store_end)\n",
    "            print('time taken: ', (store_end - store_start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "20200724_h2o4gpu",
   "language": "python",
   "name": "20200724_h2o4gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
