{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1657, 22)\n",
      "(533, 3)\n",
      "(556, 26)\n"
     ]
    }
   ],
   "source": [
    "import elasticsearch\n",
    "import pandas as pd\n",
    "from elasticsearch_dsl import Search,Q\n",
    "es = elasticsearch.Elasticsearch(['http://localhost:9200/'], maxsize=500, block=False)\n",
    "es_ma_index = 'grimoirelab_index'\n",
    "es_bl_index = 'grimoirelab_blame_index'\n",
    "# Using Elasticsearch DSL function to get the data of Commit index\n",
    "blame_es_data = Search(using=es, index=es_bl_index)\n",
    "# Loading data into a dictionary\n",
    "blame_dict = [hit.to_dict() for hit in blame_es_data.scan()]\n",
    "# Using Elasticsearch DSL function to get the data of Blame index\n",
    "commit_es_data = Search(using=es, index=es_ma_index)\n",
    "# Loading data into a dictionary\n",
    "commit_dict = [hit.to_dict() for hit in commit_es_data.scan()]\n",
    "# Creating pandas dataframe for commit data\n",
    "commit_frame = pd.DataFrame(commit_dict)\n",
    "# Creating pandas dataframe for blame data\n",
    "blame_frame = pd.DataFrame(blame_dict)\n",
    "blame_frame['file'] = blame_frame['file'].apply(lambda x:x.split('/')[-1])\n",
    "print(commit_frame.shape)\n",
    "print(blame_frame.shape)\n",
    "# Getting the blame row count. If the frmae is empty, it means all the records are clean\n",
    "blame_count = blame_frame.shape[0]\n",
    "#print(blame_frame.columns)\n",
    "\n",
    "if blame_count>0:\n",
    "    # Adding a column to Blame frame indicating that the row represents a Buggy commit\n",
    "    blame_frame['type'] = 'Buggy'\n",
    "    # Combining Commit frmae with Blame frame. An additional column called 'type' gets added to the Commit frame.\n",
    "    #comb_frame = pd.merge(commit_frame,blame_frame,how='left',left_on = ['hash','file_path'],right_on = ['blame_hash','file'])\n",
    "    comb_frame = pd.merge(commit_frame,blame_frame,how='left',left_on = ['hash','file_name'],right_on = ['blame_hash','file'])\n",
    "\n",
    "\n",
    "else:\n",
    "    # If the Blame frame is empty, no need to merge.\n",
    "    comb_frame=commit_frame\n",
    "# When merging happnes and 'type' column gets added to the main Commit frame, The rows that are not part of Blame frame are filled with 'Nan'.\n",
    "# Here, all the NaNs fro 'type' column are replaced with 'Clean' label.\n",
    "# Effectively, Each commit file (one Commit can contain more than one file) is categorised as either Buggy or Clean.\n",
    "print(comb_frame[comb_frame['type']=='Buggy'].shape)\n",
    "comb_frame['type'] = comb_frame['type'].fillna('Clean')\n",
    "\n",
    "# Cleaning and retaining the required columns\n",
    "comb_frame_refined = comb_frame[['hash', 'Author','Committer', 'Email', 'message',                               'committed_date', 'no._of_branches', 'merge_commit?',\n",
    "                                'no._of_mod_files', 'dmm_unit_size', 'dmm_unit_complexity','dmm_unit_interfacing',\n",
    "                                'file_path','file_name', 'complexity','functions', 'lines_added', 'lines_removed', 'size', 'tokens',\n",
    "                                'type']]\n",
    "# Commit hash raw value is very long. Cutting the value into first ten chars \n",
    "# Assumption is that the first ten chars rednder necessary uniqueness. May need to revisit later\n",
    "#comb_frame_refined['hash'] = comb_frame_refined['hash'].str.slice(0,10)\n",
    "\n",
    "# Changing the type from string to Data. Used Pacific time zone. Heard the pacific coast is beautiful\n",
    "commit_frame['committed_date'] = commit_frame['committed_date'].astype('str').apply(lambda x: pd.to_datetime(x).tz_convert('US/Pacific'))\n",
    "# Sorting the frame by committes date\n",
    "comb_frame_refined = comb_frame_refined.drop_duplicates().sort_values('committed_date', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613          docker/Dockerfile-full\n",
      "618                            None\n",
      "623       docker/entrypoint-full.sh\n",
      "1227                  .dockerignore\n",
      "1232                           None\n",
      "1450      docker/Dockerfile-factory\n",
      "1529    docker/Dockerfile-installed\n",
      "1533               docker/README.md\n",
      "Name: file_path, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#print(commit_frame['file_path']==blame_frame['file'])\n",
    "#blame_frame\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
